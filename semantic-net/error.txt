uv run src/measure_latency_selector.py --data_root src/dataset/RescueNet_patches/ --split test --ckpt_b0 checkpoints_segformer_b0/best_segformer_b0.pt --ckpt_b1 checkpoints_segformer_b1/best_segformer_b1.pt --selector_ckpt ../semantic-net-manylinux/checkpoints_selector/selector_lambda_0.0010.pt 
device        = cuda
data_root     = src/dataset/RescueNet_patches
split         = test
ckpt_b0       = checkpoints_segformer_b0/best_segformer_b0.pt
ckpt_b1       = checkpoints_segformer_b1/best_segformer_b1.pt
selector_ckpt = ../semantic-net-manylinux/checkpoints_selector/selector_lambda_0.0010.pt
iters         = 100
warmup        = 10
batch_size    = 1
hidden_dim    = 64
fp16          = False
dataset size (split=test) = 4600
[build] SegFormer-B0/B1 ...
[load] B0 ckpt: checkpoints_segformer_b0/best_segformer_b0.pt
/home/yamakawa-kohsuke/development/github/sslab/semantic-net/src/measure_latency_selector.py:118: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(ckpt_path, map_location=device)
[warn] missing keys in state_dict: ['segformer.encoder.patch_embeddings.0.proj.weight', 'segformer.encoder.patch_embeddings.0.proj.bias', 'segformer.encoder.patch_embeddings.0.layer_norm.weight', 'segformer.encoder.patch_embeddings.0.layer_norm.bias', 'segformer.encoder.patch_embeddings.1.proj.weight', 'segformer.encoder.patch_embeddings.1.proj.bias', 'segformer.encoder.patch_embeddings.1.layer_norm.weight', 'segformer.encoder.patch_embeddings.1.layer_norm.bias', 'segformer.encoder.patch_embeddings.2.proj.weight', 'segformer.encoder.patch_embeddings.2.proj.bias', 'segformer.encoder.patch_embeddings.2.layer_norm.weight', 'segformer.encoder.patch_embeddings.2.layer_norm.bias', 'segformer.encoder.patch_embeddings.3.proj.weight', 'segformer.encoder.patch_embeddings.3.proj.bias', 'segformer.encoder.patch_embeddings.3.layer_norm.weight', 'segformer.encoder.patch_embeddings.3.layer_norm.bias', 'segformer.encoder.block.0.0.layer_norm_1.weight', 'segformer.encoder.block.0.0.layer_norm_1.bias', 'segformer.encoder.block.0.0.attention.self.query.weight', 'segformer.encoder.block.0.0.attention.self.query.bias', 'segformer.encoder.block.0.0.attention.self.key.weight', 'segformer.encoder.block.0.0.attention.self.key.bias', 'segformer.encoder.block.0.0.attention.self.value.weight', 'segformer.encoder.block.0.0.attention.self.value.bias', 'segformer.encoder.block.0.0.attention.self.sr.weight', 'segformer.encoder.block.0.0.attention.self.sr.bias', 'segformer.encoder.block.0.0.attention.self.layer_norm.weight', 'segformer.encoder.block.0.0.attention.self.layer_norm.bias', 'segformer.encoder.block.0.0.attention.output.dense.weight', 'segformer.encoder.block.0.0.attention.output.dense.bias', 'segformer.encoder.block.0.0.layer_norm_2.weight', 'segformer.encoder.block.0.0.layer_norm_2.bias', 'segformer.encoder.block.0.0.mlp.dense1.weight', 'segformer.encoder.block.0.0.mlp.dense1.bias', 'segformer.encoder.block.0.0.mlp.dwconv.dwconv.weight', 'segformer.encoder.block.0.0.mlp.dwconv.dwconv.bias', 'segformer.encoder.block.0.0.mlp.dense2.weight', 'segformer.encoder.block.0.0.mlp.dense2.bias', 'segformer.encoder.block.0.1.layer_norm_1.weight', 'segformer.encoder.block.0.1.layer_norm_1.bias', 'segformer.encoder.block.0.1.attention.self.query.weight', 'segformer.encoder.block.0.1.attention.self.query.bias', 'segformer.encoder.block.0.1.attention.self.key.weight', 'segformer.encoder.block.0.1.attention.self.key.bias', 'segformer.encoder.block.0.1.attention.self.value.weight', 'segformer.encoder.block.0.1.attention.self.value.bias', 'segformer.encoder.block.0.1.attention.self.sr.weight', 'segformer.encoder.block.0.1.attention.self.sr.bias', 'segformer.encoder.block.0.1.attention.self.layer_norm.weight', 'segformer.encoder.block.0.1.attention.self.layer_norm.bias', 'segformer.encoder.block.0.1.attention.output.dense.weight', 'segformer.encoder.block.0.1.attention.output.dense.bias', 'segformer.encoder.block.0.1.layer_norm_2.weight', 'segformer.encoder.block.0.1.layer_norm_2.bias', 'segformer.encoder.block.0.1.mlp.dense1.weight', 'segformer.encoder.block.0.1.mlp.dense1.bias', 'segformer.encoder.block.0.1.mlp.dwconv.dwconv.weight', 'segformer.encoder.block.0.1.mlp.dwconv.dwconv.bias', 'segformer.encoder.block.0.1.mlp.dense2.weight', 'segformer.encoder.block.0.1.mlp.dense2.bias', 'segformer.encoder.block.1.0.layer_norm_1.weight', 'segformer.encoder.block.1.0.layer_norm_1.bias', 'segformer.encoder.block.1.0.attention.self.query.weight', 'segformer.encoder.block.1.0.attention.self.query.bias', 'segformer.encoder.block.1.0.attention.self.key.weight', 'segformer.encoder.block.1.0.attention.self.key.bias', 'segformer.encoder.block.1.0.attention.self.value.weight', 'segformer.encoder.block.1.0.attention.self.value.bias', 'segformer.encoder.block.1.0.attention.self.sr.weight', 'segformer.encoder.block.1.0.attention.self.sr.bias', 'segformer.encoder.block.1.0.attention.self.layer_norm.weight', 'segformer.encoder.block.1.0.attention.self.layer_norm.bias', 'segformer.encoder.block.1.0.attention.output.dense.weight', 'segformer.encoder.block.1.0.attention.output.dense.bias', 'segformer.encoder.block.1.0.layer_norm_2.weight', 'segformer.encoder.block.1.0.layer_norm_2.bias', 'segformer.encoder.block.1.0.mlp.dense1.weight', 'segformer.encoder.block.1.0.mlp.dense1.bias', 'segformer.encoder.block.1.0.mlp.dwconv.dwconv.weight', 'segformer.encoder.block.1.0.mlp.dwconv.dwconv.bias', 'segformer.encoder.block.1.0.mlp.dense2.weight', 'segformer.encoder.block.1.0.mlp.dense2.bias', 'segformer.encoder.block.1.1.layer_norm_1.weight', 'segformer.encoder.block.1.1.layer_norm_1.bias', 'segformer.encoder.block.1.1.attention.self.query.weight', 'segformer.encoder.block.1.1.attention.self.query.bias', 'segformer.encoder.block.1.1.attention.self.key.weight', 'segformer.encoder.block.1.1.attention.self.key.bias', 'segformer.encoder.block.1.1.attention.self.value.weight', 'segformer.encoder.block.1.1.attention.self.value.bias', 'segformer.encoder.block.1.1.attention.self.sr.weight', 'segformer.encoder.block.1.1.attention.self.sr.bias', 'segformer.encoder.block.1.1.attention.self.layer_norm.weight', 'segformer.encoder.block.1.1.attention.self.layer_norm.bias', 'segformer.encoder.block.1.1.attention.output.dense.weight', 'segformer.encoder.block.1.1.attention.output.dense.bias', 'segformer.encoder.block.1.1.layer_norm_2.weight', 'segformer.encoder.block.1.1.layer_norm_2.bias', 'segformer.encoder.block.1.1.mlp.dense1.weight', 'segformer.encoder.block.1.1.mlp.dense1.bias', 'segformer.encoder.block.1.1.mlp.dwconv.dwconv.weight', 'segformer.encoder.block.1.1.mlp.dwconv.dwconv.bias', 'segformer.encoder.block.1.1.mlp.dense2.weight', 'segformer.encoder.block.1.1.mlp.dense2.bias', 'segformer.encoder.block.2.0.layer_norm_1.weight', 'segformer.encoder.block.2.0.layer_norm_1.bias', 'segformer.encoder.block.2.0.attention.self.query.weight', 'segformer.encoder.block.2.0.attention.self.query.bias', 'segformer.encoder.block.2.0.attention.self.key.weight', 'segformer.encoder.block.2.0.attention.self.key.bias', 'segformer.encoder.block.2.0.attention.self.value.weight', 'segformer.encoder.block.2.0.attention.self.value.bias', 'segformer.encoder.block.2.0.attention.self.sr.weight', 'segformer.encoder.block.2.0.attention.self.sr.bias', 'segformer.encoder.block.2.0.attention.self.layer_norm.weight', 'segformer.encoder.block.2.0.attention.self.layer_norm.bias', 'segformer.encoder.block.2.0.attention.output.dense.weight', 'segformer.encoder.block.2.0.attention.output.dense.bias', 'segformer.encoder.block.2.0.layer_norm_2.weight', 'segformer.encoder.block.2.0.layer_norm_2.bias', 'segformer.encoder.block.2.0.mlp.dense1.weight', 'segformer.encoder.block.2.0.mlp.dense1.bias', 'segformer.encoder.block.2.0.mlp.dwconv.dwconv.weight', 'segformer.encoder.block.2.0.mlp.dwconv.dwconv.bias', 'segformer.encoder.block.2.0.mlp.dense2.weight', 'segformer.encoder.block.2.0.mlp.dense2.bias', 'segformer.encoder.block.2.1.layer_norm_1.weight', 'segformer.encoder.block.2.1.layer_norm_1.bias', 'segformer.encoder.block.2.1.attention.self.query.weight', 'segformer.encoder.block.2.1.attention.self.query.bias', 'segformer.encoder.block.2.1.attention.self.key.weight', 'segformer.encoder.block.2.1.attention.self.key.bias', 'segformer.encoder.block.2.1.attention.self.value.weight', 'segformer.encoder.block.2.1.attention.self.value.bias', 'segformer.encoder.block.2.1.attention.self.sr.weight', 'segformer.encoder.block.2.1.attention.self.sr.bias', 'segformer.encoder.block.2.1.attention.self.layer_norm.weight', 'segformer.encoder.block.2.1.attention.self.layer_norm.bias', 'segformer.encoder.block.2.1.attention.output.dense.weight', 'segformer.encoder.block.2.1.attention.output.dense.bias', 'segformer.encoder.block.2.1.layer_norm_2.weight', 'segformer.encoder.block.2.1.layer_norm_2.bias', 'segformer.encoder.block.2.1.mlp.dense1.weight', 'segformer.encoder.block.2.1.mlp.dense1.bias', 'segformer.encoder.block.2.1.mlp.dwconv.dwconv.weight', 'segformer.encoder.block.2.1.mlp.dwconv.dwconv.bias', 'segformer.encoder.block.2.1.mlp.dense2.weight', 'segformer.encoder.block.2.1.mlp.dense2.bias', 'segformer.encoder.block.3.0.layer_norm_1.weight', 'segformer.encoder.block.3.0.layer_norm_1.bias', 'segformer.encoder.block.3.0.attention.self.query.weight', 'segformer.encoder.block.3.0.attention.self.query.bias', 'segformer.encoder.block.3.0.attention.self.key.weight', 'segformer.encoder.block.3.0.attention.self.key.bias', 'segformer.encoder.block.3.0.attention.self.value.weight', 'segformer.encoder.block.3.0.attention.self.value.bias', 'segformer.encoder.block.3.0.attention.output.dense.weight', 'segformer.encoder.block.3.0.attention.output.dense.bias', 'segformer.encoder.block.3.0.layer_norm_2.weight', 'segformer.encoder.block.3.0.layer_norm_2.bias', 'segformer.encoder.block.3.0.mlp.dense1.weight', 'segformer.encoder.block.3.0.mlp.dense1.bias', 'segformer.encoder.block.3.0.mlp.dwconv.dwconv.weight', 'segformer.encoder.block.3.0.mlp.dwconv.dwconv.bias', 'segformer.encoder.block.3.0.mlp.dense2.weight', 'segformer.encoder.block.3.0.mlp.dense2.bias', 'segformer.encoder.block.3.1.layer_norm_1.weight', 'segformer.encoder.block.3.1.layer_norm_1.bias', 'segformer.encoder.block.3.1.attention.self.query.weight', 'segformer.encoder.block.3.1.attention.self.query.bias', 'segformer.encoder.block.3.1.attention.self.key.weight', 'segformer.encoder.block.3.1.attention.self.key.bias', 'segformer.encoder.block.3.1.attention.self.value.weight', 'segformer.encoder.block.3.1.attention.self.value.bias', 'segformer.encoder.block.3.1.attention.output.dense.weight', 'segformer.encoder.block.3.1.attention.output.dense.bias', 'segformer.encoder.block.3.1.layer_norm_2.weight', 'segformer.encoder.block.3.1.layer_norm_2.bias', 'segformer.encoder.block.3.1.mlp.dense1.weight', 'segformer.encoder.block.3.1.mlp.dense1.bias', 'segformer.encoder.block.3.1.mlp.dwconv.dwconv.weight', 'segformer.encoder.block.3.1.mlp.dwconv.dwconv.bias', 'segformer.encoder.block.3.1.mlp.dense2.weight', 'segformer.encoder.block.3.1.mlp.dense2.bias', 'segformer.encoder.layer_norm.0.weight', 'segformer.encoder.layer_norm.0.bias', 'segformer.encoder.layer_norm.1.weight', 'segformer.encoder.layer_norm.1.bias', 'segformer.encoder.layer_norm.2.weight', 'segformer.encoder.layer_norm.2.bias', 'segformer.encoder.layer_norm.3.weight', 'segformer.encoder.layer_norm.3.bias', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_fuse.weight', 'decode_head.batch_norm.weight', 'decode_head.batch_norm.bias', 'decode_head.batch_norm.running_mean', 'decode_head.batch_norm.running_var', 'decode_head.classifier.weight', 'decode_head.classifier.bias']
[warn] unexpected keys in state_dict: ['epoch', 'model_state_dict', 'optimizer_state_dict', 'best_miou', 'args']
[load] B1 ckpt: checkpoints_segformer_b1/best_segformer_b1.pt
[warn] missing keys in state_dict: ['segformer.encoder.patch_embeddings.0.proj.weight', 'segformer.encoder.patch_embeddings.0.proj.bias', 'segformer.encoder.patch_embeddings.0.layer_norm.weight', 'segformer.encoder.patch_embeddings.0.layer_norm.bias', 'segformer.encoder.patch_embeddings.1.proj.weight', 'segformer.encoder.patch_embeddings.1.proj.bias', 'segformer.encoder.patch_embeddings.1.layer_norm.weight', 'segformer.encoder.patch_embeddings.1.layer_norm.bias', 'segformer.encoder.patch_embeddings.2.proj.weight', 'segformer.encoder.patch_embeddings.2.proj.bias', 'segformer.encoder.patch_embeddings.2.layer_norm.weight', 'segformer.encoder.patch_embeddings.2.layer_norm.bias', 'segformer.encoder.patch_embeddings.3.proj.weight', 'segformer.encoder.patch_embeddings.3.proj.bias', 'segformer.encoder.patch_embeddings.3.layer_norm.weight', 'segformer.encoder.patch_embeddings.3.layer_norm.bias', 'segformer.encoder.block.0.0.layer_norm_1.weight', 'segformer.encoder.block.0.0.layer_norm_1.bias', 'segformer.encoder.block.0.0.attention.self.query.weight', 'segformer.encoder.block.0.0.attention.self.query.bias', 'segformer.encoder.block.0.0.attention.self.key.weight', 'segformer.encoder.block.0.0.attention.self.key.bias', 'segformer.encoder.block.0.0.attention.self.value.weight', 'segformer.encoder.block.0.0.attention.self.value.bias', 'segformer.encoder.block.0.0.attention.self.sr.weight', 'segformer.encoder.block.0.0.attention.self.sr.bias', 'segformer.encoder.block.0.0.attention.self.layer_norm.weight', 'segformer.encoder.block.0.0.attention.self.layer_norm.bias', 'segformer.encoder.block.0.0.attention.output.dense.weight', 'segformer.encoder.block.0.0.attention.output.dense.bias', 'segformer.encoder.block.0.0.layer_norm_2.weight', 'segformer.encoder.block.0.0.layer_norm_2.bias', 'segformer.encoder.block.0.0.mlp.dense1.weight', 'segformer.encoder.block.0.0.mlp.dense1.bias', 'segformer.encoder.block.0.0.mlp.dwconv.dwconv.weight', 'segformer.encoder.block.0.0.mlp.dwconv.dwconv.bias', 'segformer.encoder.block.0.0.mlp.dense2.weight', 'segformer.encoder.block.0.0.mlp.dense2.bias', 'segformer.encoder.block.0.1.layer_norm_1.weight', 'segformer.encoder.block.0.1.layer_norm_1.bias', 'segformer.encoder.block.0.1.attention.self.query.weight', 'segformer.encoder.block.0.1.attention.self.query.bias', 'segformer.encoder.block.0.1.attention.self.key.weight', 'segformer.encoder.block.0.1.attention.self.key.bias', 'segformer.encoder.block.0.1.attention.self.value.weight', 'segformer.encoder.block.0.1.attention.self.value.bias', 'segformer.encoder.block.0.1.attention.self.sr.weight', 'segformer.encoder.block.0.1.attention.self.sr.bias', 'segformer.encoder.block.0.1.attention.self.layer_norm.weight', 'segformer.encoder.block.0.1.attention.self.layer_norm.bias', 'segformer.encoder.block.0.1.attention.output.dense.weight', 'segformer.encoder.block.0.1.attention.output.dense.bias', 'segformer.encoder.block.0.1.layer_norm_2.weight', 'segformer.encoder.block.0.1.layer_norm_2.bias', 'segformer.encoder.block.0.1.mlp.dense1.weight', 'segformer.encoder.block.0.1.mlp.dense1.bias', 'segformer.encoder.block.0.1.mlp.dwconv.dwconv.weight', 'segformer.encoder.block.0.1.mlp.dwconv.dwconv.bias', 'segformer.encoder.block.0.1.mlp.dense2.weight', 'segformer.encoder.block.0.1.mlp.dense2.bias', 'segformer.encoder.block.1.0.layer_norm_1.weight', 'segformer.encoder.block.1.0.layer_norm_1.bias', 'segformer.encoder.block.1.0.attention.self.query.weight', 'segformer.encoder.block.1.0.attention.self.query.bias', 'segformer.encoder.block.1.0.attention.self.key.weight', 'segformer.encoder.block.1.0.attention.self.key.bias', 'segformer.encoder.block.1.0.attention.self.value.weight', 'segformer.encoder.block.1.0.attention.self.value.bias', 'segformer.encoder.block.1.0.attention.self.sr.weight', 'segformer.encoder.block.1.0.attention.self.sr.bias', 'segformer.encoder.block.1.0.attention.self.layer_norm.weight', 'segformer.encoder.block.1.0.attention.self.layer_norm.bias', 'segformer.encoder.block.1.0.attention.output.dense.weight', 'segformer.encoder.block.1.0.attention.output.dense.bias', 'segformer.encoder.block.1.0.layer_norm_2.weight', 'segformer.encoder.block.1.0.layer_norm_2.bias', 'segformer.encoder.block.1.0.mlp.dense1.weight', 'segformer.encoder.block.1.0.mlp.dense1.bias', 'segformer.encoder.block.1.0.mlp.dwconv.dwconv.weight', 'segformer.encoder.block.1.0.mlp.dwconv.dwconv.bias', 'segformer.encoder.block.1.0.mlp.dense2.weight', 'segformer.encoder.block.1.0.mlp.dense2.bias', 'segformer.encoder.block.1.1.layer_norm_1.weight', 'segformer.encoder.block.1.1.layer_norm_1.bias', 'segformer.encoder.block.1.1.attention.self.query.weight', 'segformer.encoder.block.1.1.attention.self.query.bias', 'segformer.encoder.block.1.1.attention.self.key.weight', 'segformer.encoder.block.1.1.attention.self.key.bias', 'segformer.encoder.block.1.1.attention.self.value.weight', 'segformer.encoder.block.1.1.attention.self.value.bias', 'segformer.encoder.block.1.1.attention.self.sr.weight', 'segformer.encoder.block.1.1.attention.self.sr.bias', 'segformer.encoder.block.1.1.attention.self.layer_norm.weight', 'segformer.encoder.block.1.1.attention.self.layer_norm.bias', 'segformer.encoder.block.1.1.attention.output.dense.weight', 'segformer.encoder.block.1.1.attention.output.dense.bias', 'segformer.encoder.block.1.1.layer_norm_2.weight', 'segformer.encoder.block.1.1.layer_norm_2.bias', 'segformer.encoder.block.1.1.mlp.dense1.weight', 'segformer.encoder.block.1.1.mlp.dense1.bias', 'segformer.encoder.block.1.1.mlp.dwconv.dwconv.weight', 'segformer.encoder.block.1.1.mlp.dwconv.dwconv.bias', 'segformer.encoder.block.1.1.mlp.dense2.weight', 'segformer.encoder.block.1.1.mlp.dense2.bias', 'segformer.encoder.block.2.0.layer_norm_1.weight', 'segformer.encoder.block.2.0.layer_norm_1.bias', 'segformer.encoder.block.2.0.attention.self.query.weight', 'segformer.encoder.block.2.0.attention.self.query.bias', 'segformer.encoder.block.2.0.attention.self.key.weight', 'segformer.encoder.block.2.0.attention.self.key.bias', 'segformer.encoder.block.2.0.attention.self.value.weight', 'segformer.encoder.block.2.0.attention.self.value.bias', 'segformer.encoder.block.2.0.attention.self.sr.weight', 'segformer.encoder.block.2.0.attention.self.sr.bias', 'segformer.encoder.block.2.0.attention.self.layer_norm.weight', 'segformer.encoder.block.2.0.attention.self.layer_norm.bias', 'segformer.encoder.block.2.0.attention.output.dense.weight', 'segformer.encoder.block.2.0.attention.output.dense.bias', 'segformer.encoder.block.2.0.layer_norm_2.weight', 'segformer.encoder.block.2.0.layer_norm_2.bias', 'segformer.encoder.block.2.0.mlp.dense1.weight', 'segformer.encoder.block.2.0.mlp.dense1.bias', 'segformer.encoder.block.2.0.mlp.dwconv.dwconv.weight', 'segformer.encoder.block.2.0.mlp.dwconv.dwconv.bias', 'segformer.encoder.block.2.0.mlp.dense2.weight', 'segformer.encoder.block.2.0.mlp.dense2.bias', 'segformer.encoder.block.2.1.layer_norm_1.weight', 'segformer.encoder.block.2.1.layer_norm_1.bias', 'segformer.encoder.block.2.1.attention.self.query.weight', 'segformer.encoder.block.2.1.attention.self.query.bias', 'segformer.encoder.block.2.1.attention.self.key.weight', 'segformer.encoder.block.2.1.attention.self.key.bias', 'segformer.encoder.block.2.1.attention.self.value.weight', 'segformer.encoder.block.2.1.attention.self.value.bias', 'segformer.encoder.block.2.1.attention.self.sr.weight', 'segformer.encoder.block.2.1.attention.self.sr.bias', 'segformer.encoder.block.2.1.attention.self.layer_norm.weight', 'segformer.encoder.block.2.1.attention.self.layer_norm.bias', 'segformer.encoder.block.2.1.attention.output.dense.weight', 'segformer.encoder.block.2.1.attention.output.dense.bias', 'segformer.encoder.block.2.1.layer_norm_2.weight', 'segformer.encoder.block.2.1.layer_norm_2.bias', 'segformer.encoder.block.2.1.mlp.dense1.weight', 'segformer.encoder.block.2.1.mlp.dense1.bias', 'segformer.encoder.block.2.1.mlp.dwconv.dwconv.weight', 'segformer.encoder.block.2.1.mlp.dwconv.dwconv.bias', 'segformer.encoder.block.2.1.mlp.dense2.weight', 'segformer.encoder.block.2.1.mlp.dense2.bias', 'segformer.encoder.block.3.0.layer_norm_1.weight', 'segformer.encoder.block.3.0.layer_norm_1.bias', 'segformer.encoder.block.3.0.attention.self.query.weight', 'segformer.encoder.block.3.0.attention.self.query.bias', 'segformer.encoder.block.3.0.attention.self.key.weight', 'segformer.encoder.block.3.0.attention.self.key.bias', 'segformer.encoder.block.3.0.attention.self.value.weight', 'segformer.encoder.block.3.0.attention.self.value.bias', 'segformer.encoder.block.3.0.attention.output.dense.weight', 'segformer.encoder.block.3.0.attention.output.dense.bias', 'segformer.encoder.block.3.0.layer_norm_2.weight', 'segformer.encoder.block.3.0.layer_norm_2.bias', 'segformer.encoder.block.3.0.mlp.dense1.weight', 'segformer.encoder.block.3.0.mlp.dense1.bias', 'segformer.encoder.block.3.0.mlp.dwconv.dwconv.weight', 'segformer.encoder.block.3.0.mlp.dwconv.dwconv.bias', 'segformer.encoder.block.3.0.mlp.dense2.weight', 'segformer.encoder.block.3.0.mlp.dense2.bias', 'segformer.encoder.block.3.1.layer_norm_1.weight', 'segformer.encoder.block.3.1.layer_norm_1.bias', 'segformer.encoder.block.3.1.attention.self.query.weight', 'segformer.encoder.block.3.1.attention.self.query.bias', 'segformer.encoder.block.3.1.attention.self.key.weight', 'segformer.encoder.block.3.1.attention.self.key.bias', 'segformer.encoder.block.3.1.attention.self.value.weight', 'segformer.encoder.block.3.1.attention.self.value.bias', 'segformer.encoder.block.3.1.attention.output.dense.weight', 'segformer.encoder.block.3.1.attention.output.dense.bias', 'segformer.encoder.block.3.1.layer_norm_2.weight', 'segformer.encoder.block.3.1.layer_norm_2.bias', 'segformer.encoder.block.3.1.mlp.dense1.weight', 'segformer.encoder.block.3.1.mlp.dense1.bias', 'segformer.encoder.block.3.1.mlp.dwconv.dwconv.weight', 'segformer.encoder.block.3.1.mlp.dwconv.dwconv.bias', 'segformer.encoder.block.3.1.mlp.dense2.weight', 'segformer.encoder.block.3.1.mlp.dense2.bias', 'segformer.encoder.layer_norm.0.weight', 'segformer.encoder.layer_norm.0.bias', 'segformer.encoder.layer_norm.1.weight', 'segformer.encoder.layer_norm.1.bias', 'segformer.encoder.layer_norm.2.weight', 'segformer.encoder.layer_norm.2.bias', 'segformer.encoder.layer_norm.3.weight', 'segformer.encoder.layer_norm.3.bias', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_fuse.weight', 'decode_head.batch_norm.weight', 'decode_head.batch_norm.bias', 'decode_head.batch_norm.running_mean', 'decode_head.batch_norm.running_var', 'decode_head.classifier.weight', 'decode_head.classifier.bias']
[warn] unexpected keys in state_dict: ['epoch', 'model_state_dict', 'optimizer_state_dict', 'best_miou', 'args']
[load] selector ckpt: ../semantic-net-manylinux/checkpoints_selector/selector_lambda_0.0010.pt
/home/yamakawa-kohsuke/development/github/sslab/semantic-net/src/measure_latency_selector.py:234: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  selector.load_state_dict(torch.load(selector_ckpt, map_location=device))
Traceback (most recent call last):
  File "/home/yamakawa-kohsuke/development/github/sslab/semantic-net/src/measure_latency_selector.py", line 429, in <module>
    main()
  File "/home/yamakawa-kohsuke/development/github/sslab/semantic-net/src/measure_latency_selector.py", line 411, in main
    measure_latency_selector(
  File "/home/yamakawa-kohsuke/development/github/sslab/semantic-net/src/measure_latency_selector.py", line 234, in measure_latency_selector
    selector.load_state_dict(torch.load(selector_ckpt, map_location=device))
  File "/home/yamakawa-kohsuke/development/github/sslab/semantic-net/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2477, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for SelectorMLP:
	Missing key(s) in state_dict: "net.4.weight", "net.4.bias". 
	size mismatch for net.2.weight: copying a param with shape torch.Size([2, 64]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for net.2.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([64]).

