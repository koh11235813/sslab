yamakawa-kohsuke@yamakawakohsuke-jetson:~/development/github/sslab/semantic-net$ uv run --frozen src/measure_latency-IoU_selector.py --data_root src/dataset/RescueNet_patches/ --split test --ckpt_b0 ../semantic-net-manylinux/checkpoints_segformer_b0/best_segformer_b0.pt --ckpt_b1 ../semantic-net-manylinux/checkpoints_segformer_b1/best_segformer_b1.pt --selector_ckpt ../semantic-net-manylinux/checkpoints_selector/selector_lambda_0.0010.pt --precomputed_csv ../semantic-net-manylinux/precomputed_values_rescuenet_b0_b1.csv 
device        = cuda
data_root     = src/dataset/RescueNet_patches
split         = test
ckpt_b0       = ../semantic-net-manylinux/checkpoints_segformer_b0/best_segformer_b0.pt
ckpt_b1       = ../semantic-net-manylinux/checkpoints_segformer_b1/best_segformer_b1.pt
selector_ckpt = ../semantic-net-manylinux/checkpoints_selector/selector_lambda_0.0010.pt
iters         = 100
warmup        = 10
batch_size    = 1
hidden_dim    = 64
fp16          = False
csv           = ../semantic-net-manylinux/precomputed_values_rescuenet_b0_b1.csv
[build] SegFormer-B0 / B1
/home/yamakawa-kohsuke/development/github/sslab/semantic-net/src/measure_latency-IoU_selector.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(ckpt_path, map_location=device)
[build] Selector MLP
/home/yamakawa-kohsuke/development/github/sslab/semantic-net/src/measure_latency-IoU_selector.py:346: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  sel_state = torch.load(selector_ckpt, map_location=device)
[dataset] split=test, size=4600
[amp] fp32 (no autocast) for selector pipeline
[metrics] load precomputed metrics from: ../semantic-net-manylinux/precomputed_values_rescuenet_b0_b1.csv

=== selector pipeline latency (Jetson) ===
  device        : cuda
  split         : test
  batch_size    : 1
  fp16          : False
  warmup        : 10
  iters         : 100
  #samples used : 100
  #B1 calls     : 97  (0.970 per sample)
  mean latency  : 97.806 ms
  p50 latency   : 97.919 ms
  p90 latency   : 102.628 ms

[IoU] no samples matched in precomputed CSV -> IoU stats skipped

[done] total elapsed wall time = 39.2 sec
yamakawa-kohsuke@yamakawakohsuke-jetson:~/development/github/sslab/semantic-net$ uv run --frozen src/measure_latency-IoU_selector.py --data_root src/dataset/RescueNet_patches/ --split test --ckpt_b0 ../semantic-net-manylinux/checkpoints_segformer_b0/best_segformer_b0.pt --ckpt_b1 ../semantic-net-manylinux/checkpoints_segformer_b1/best_segformer_b1.pt --selector_ckpt ../semantic-net-manylinux/checkpoints_selector/selector_lambda_0.0050.pt --precomputed_csv ../semantic-net-manylinux/precomputed_values_rescuenet_b0_b1.csv 
device        = cuda
data_root     = src/dataset/RescueNet_patches
split         = test
ckpt_b0       = ../semantic-net-manylinux/checkpoints_segformer_b0/best_segformer_b0.pt
ckpt_b1       = ../semantic-net-manylinux/checkpoints_segformer_b1/best_segformer_b1.pt
selector_ckpt = ../semantic-net-manylinux/checkpoints_selector/selector_lambda_0.0050.pt
iters         = 100
warmup        = 10
batch_size    = 1
hidden_dim    = 64
fp16          = False
csv           = ../semantic-net-manylinux/precomputed_values_rescuenet_b0_b1.csv
[build] SegFormer-B0 / B1
/home/yamakawa-kohsuke/development/github/sslab/semantic-net/src/measure_latency-IoU_selector.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(ckpt_path, map_location=device)
[build] Selector MLP
/home/yamakawa-kohsuke/development/github/sslab/semantic-net/src/measure_latency-IoU_selector.py:346: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  sel_state = torch.load(selector_ckpt, map_location=device)
[dataset] split=test, size=4600
[amp] fp32 (no autocast) for selector pipeline
[metrics] load precomputed metrics from: ../semantic-net-manylinux/precomputed_values_rescuenet_b0_b1.csv

=== selector pipeline latency (Jetson) ===
  device        : cuda
  split         : test
  batch_size    : 1
  fp16          : False
  warmup        : 10
  iters         : 100
  #samples used : 100
  #B1 calls     : 85  (0.850 per sample)
  mean latency  : 90.014 ms
  p50 latency   : 97.547 ms
  p90 latency   : 101.969 ms

[IoU] no samples matched in precomputed CSV -> IoU stats skipped

[done] total elapsed wall time = 35.6 sec
yamakawa-kohsuke@yamakawakohsuke-jetson:~/development/github/sslab/semantic-net$ uv run --frozen src/measure_latency-IoU_selector.py --data_root src/dataset/RescueNet_patches/ --split val --ckpt_b0 ../semantic-net-manylinux/checkpoints_segformer_b0/best_segformer_b0.pt --ckpt_b1 ../semantic-net-manylinux/checkpoints_segformer_b1/best_segformer_b1.pt --selector_ckpt ../semantic-net-manylinux/checkpoints_selector/selector_lambda_0.0010.pt --precomputed_csv ../semantic-net-manylinux/precomputed_values_rescuenet_b0_b1.csv 
device        = cuda
data_root     = src/dataset/RescueNet_patches
split         = val
ckpt_b0       = ../semantic-net-manylinux/checkpoints_segformer_b0/best_segformer_b0.pt
ckpt_b1       = ../semantic-net-manylinux/checkpoints_segformer_b1/best_segformer_b1.pt
selector_ckpt = ../semantic-net-manylinux/checkpoints_selector/selector_lambda_0.0010.pt
iters         = 100
warmup        = 10
batch_size    = 1
hidden_dim    = 64
fp16          = False
csv           = ../semantic-net-manylinux/precomputed_values_rescuenet_b0_b1.csv
[build] SegFormer-B0 / B1
/home/yamakawa-kohsuke/development/github/sslab/semantic-net/src/measure_latency-IoU_selector.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(ckpt_path, map_location=device)
[build] Selector MLP
/home/yamakawa-kohsuke/development/github/sslab/semantic-net/src/measure_latency-IoU_selector.py:346: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  sel_state = torch.load(selector_ckpt, map_location=device)
[dataset] split=val, size=4470
[amp] fp32 (no autocast) for selector pipeline
[metrics] load precomputed metrics from: ../semantic-net-manylinux/precomputed_values_rescuenet_b0_b1.csv

=== selector pipeline latency (Jetson) ===
  device        : cuda
  split         : val
  batch_size    : 1
  fp16          : False
  warmup        : 10
  iters         : 100
  #samples used : 100
  #B1 calls     : 93  (0.930 per sample)
  mean latency  : 95.949 ms
  p50 latency   : 98.869 ms
  p90 latency   : 103.539 ms

[IoU] no samples matched in precomputed CSV -> IoU stats skipped

[done] total elapsed wall time = 37.7 sec
yamakawa-kohsuke@yamakawakohsuke-jetson:~/development/github/sslab/semantic-net$ uv run --frozen src/measure_latency-IoU_selector.py --data_root src/dataset/RescueNet_patches/ --split test --ckpt_b0 ../semantic-net-manylinux/checkpoints_segformer_b0/best_segformer_b0.pt --ckpt_b1 ../semantic-net-manylinux/checkpoints_segformer_b1/best_segformer_b1.pt --selector_ckpt ../semantic-net-manylinux/checkpoints_selector/selector_lambda_0.0010.pt --precomputed_csv ../semantic-net-manylinux/precomputed_values_rescuenet_b0_b1.csv 
device        = cuda
data_root     = src/dataset/RescueNet_patches
split         = test
ckpt_b0       = ../semantic-net-manylinux/checkpoints_segformer_b0/best_segformer_b0.pt
ckpt_b1       = ../semantic-net-manylinux/checkpoints_segformer_b1/best_segformer_b1.pt
selector_ckpt = ../semantic-net-manylinux/checkpoints_selector/selector_lambda_0.0010.pt
iters         = 100
warmup        = 10
batch_size    = 1
hidden_dim    = 64
fp16          = False
csv           = ../semantic-net-manylinux/precomputed_values_rescuenet_b0_b1.csv
[build] SegFormer-B0 / B1
/home/yamakawa-kohsuke/development/github/sslab/semantic-net/src/measure_latency-IoU_selector.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  ckpt = torch.load(ckpt_path, map_location=device)
[build] Selector MLP
/home/yamakawa-kohsuke/development/github/sslab/semantic-net/src/measure_latency-IoU_selector.py:346: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  sel_state = torch.load(selector_ckpt, map_location=device)
[dataset] split=test, size=4600
[amp] fp32 (no autocast) for selector pipeline
[metrics] load precomputed metrics from: ../semantic-net-manylinux/precomputed_values_rescuenet_b0_b1.csv

=== selector pipeline latency (Jetson) ===
  device        : cuda
  split         : test
  batch_size    : 1
  fp16          : False
  warmup        : 10
  iters         : 100
  #samples used : 100
  #B1 calls     : 97  (0.970 per sample)
  mean latency  : 97.276 ms
  p50 latency   : 97.824 ms
  p90 latency   : 102.410 ms

[IoU] no samples matched in precomputed CSV -> IoU stats skipped

[done] total elapsed wall time = 36.1 sec

